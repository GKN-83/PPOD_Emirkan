{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Assignment #2-3: Anonymisation\n",
    "- Dataset: Crossfit [Daset](https://data.world/bgadoci/crossfit-data) (In this assignment only the athletes file was used) \n",
    "- Credits: Dataset was put together by Sam Swift\n",
    "- ToDo: To run the jupyter notebook the requirements.txt need be installed (`pip install -r requirements.txt`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read csv as dataframe\n",
    "df = pd.read_csv(\"athletes.csv\", low_memory=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T13:16:41.574410300Z",
     "start_time": "2024-01-12T13:16:39.511514600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First Step: Revisit the data set to remind ourselves what we are working with\n",
    "- For a better understanding of the structure of the dataset , we display the attribute values\n",
    "    - What columns does the dataset contain and in what format are the attribute values?\n",
    "        - Therefore, each column and the first value of each column (which is not empty or Null) is printed\n",
    "- We've already worked with this dataset, so we won't go into detail"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: 'athlete_id', Example Data: 2554.0\n",
      "Column: 'name', Example Data: Pj Ablang\n",
      "Column: 'region', Example Data: South West\n",
      "Column: 'team', Example Data: Double Edge\n",
      "Column: 'affiliate', Example Data: Double Edge CrossFit\n",
      "Column: 'gender', Example Data: Male\n",
      "Column: 'age', Example Data: 24.0\n",
      "Column: 'height', Example Data: 70.0\n",
      "Column: 'weight', Example Data: 166.0\n",
      "Column: 'fran', Example Data: 211.0\n",
      "Column: 'helen', Example Data: 645.0\n",
      "Column: 'grace', Example Data: 300.0\n",
      "Column: 'filthy50', Example Data: 1053.0\n",
      "Column: 'fgonebad', Example Data: 0.0\n",
      "Column: 'run400', Example Data: 61.0\n",
      "Column: 'run5k', Example Data: 1081.0\n",
      "Column: 'candj', Example Data: 220.0\n",
      "Column: 'snatch', Example Data: 200.0\n",
      "Column: 'deadlift', Example Data: 400.0\n",
      "Column: 'backsq', Example Data: 305.0\n",
      "Column: 'pullups', Example Data: 25.0\n",
      "Column: 'eat', Example Data: I eat 1-3 full cheat meals per week|\n",
      "Column: 'train', Example Data: I workout mostly at a CrossFit Affiliate|I have a coach who determines my programming|I record my workouts|\n",
      "Column: 'background', Example Data: I played youth or high school level sports|I regularly play recreational sports|\n",
      "Column: 'experience', Example Data: I began CrossFit with a coach (e.g. at an affiliate)|I have attended one or more specialty courses|I have had a life changing experience due to CrossFit|\n",
      "Column: 'schedule', Example Data: I do multiple workouts in a day 2x a week|\n",
      "Column: 'howlong', Example Data: 4+ years|\n",
      "Column: 'retrieved_datetime', Example Data: 2015-03-01 22:49:18\n"
     ]
    }
   ],
   "source": [
    "def get_first_not_not_empty_value(df_column):\n",
    "    return df_column.dropna().iloc[0] if not df_column.dropna().empty else None\n",
    "\n",
    "# Iterate each column \n",
    "for column in df.columns:\n",
    "    first_value = get_first_not_not_empty_value(df[column])\n",
    "    print(f\"Column: '{column}', Example Data: {first_value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T13:16:41.938201500Z",
     "start_time": "2024-01-12T13:16:41.568504400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 Anonymisation: Bare Bones – 10 marks\n",
    "To get a better understanding of what we meant, we've directly applied our proposed algorithm to reach k-anonymity to the given dataset futher down in this file while explaining what we did while coding. \n",
    "The goal of k-anonymity is to modify a dataset such that any given record cannot be distinguished from at least k−1 other records regarding certain \"quasi-identifier\" attributes. \n",
    "\n",
    "### 3.1.1 Our Algorithm Steps: \n",
    "1. Identify the direct identifier attributes in the data set.\n",
    "2. Identify the quasi-identifiers attributes in the dataset.\n",
    "3. Apply k-anonymity: Choose a value for k (size of the groups of indistinguishable records)\n",
    "   - The smaller k, the lower the anonymity -> less information loss\n",
    "4. Use Generalization, Aggregation and Suppression as the transformation methods to transform each of the quasi-identifiers\n",
    "   - Start with aggregating numeric attributes (those are fitting for aggregation)\n",
    "   - Proceed with suppressing values that very rarely occur (these might identify an individual directly)\n",
    "   - map categoric attributes to other, broader categories (to reduce unique values per column)\n",
    "   - Goal in this step: Get the unique values per column as low as possible without losing too much information\n",
    "5. Ensure that there are at least k records for each combination of quasi-identifiers\n",
    "   - If not, drop the records that don't have at least k duplicates regarding the quasi identifiers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1.2 Discussion of pros and cons of the algorithm with respect to the dataset\n",
    "1. Pros\n",
    "   - The primary advantage of applying k-anonymity is the significant enhancement of privacy. This algorithm ensures that individual athletes cannot be easily identified based on quasi-identifiers. This is the main goal. By generalizing and categorizing attributes in a non automatic way, the dataset has the potential of not losing too much information.\n",
    "2. Cons\n",
    "   - The major drawback is the loss of information. In the pursuit of anonymity, detailed data is generalized or suppressed, which can lead to the loss of potentially valuable insights. Especially the last step, where columns not meeting the k-criteria get removed, a lot of information might be lost. Also, the process of suppressing rarely occuring data might introduce biases, as certain groups or unusual data points might be disproportionately suppressed. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2.1 Applying the algorithm to our dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Identify  direct identifier attributes\n",
    "- By inspecting the different columns and the data format, several attributes which have the potential to contain explicit personally identifiable information can be identified\n",
    "    - `athelete_id`\n",
    "        -  This really depends on the usage of this id! Considerations to take into account are: \n",
    "            - Is the `athlete_id` only used as an internal id of this dataset or does it maybe even refer to an official id?\n",
    "            - Are there other datasets available which may have a similar source to this dataset? Thus, these other datasets may use the same `athlete_id`\n",
    "    - `name`\n",
    "        - The name allows to identify an individual\n",
    "    - `team`\n",
    "        - Depending on the size of the team, this could allow to identify a specific athlete\n",
    "    - `affiliate` \n",
    "        - Depending on the affiliate and the amount of contracted athletes, this could allow to identify an individual\n",
    "    - All stats of the athletes\n",
    "        - If an athlete has really remarkable stats (maybe even a world record in a category), this could allow to identify the individual\n",
    "    - `train` \n",
    "        - If an athlete has a special and famous training routine, this could allow to identify him\n",
    "    - `background`\n",
    "        - If an athlete has a famous background or mentions names, this could allow to identify him\n",
    "    - `experience`\n",
    "        - If an athlete mentions concrete information about his experience (e.g. name of current coach), this could allow to identify him\n",
    "\n",
    "-> As can be seen, all columns could potentially contain outliers which could be then used to identify an individual. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Identify the quasi-identifiers attributes in the dataset\n",
    "- In this step, we use the following script to search for any attributes qualifying as a quasi-identifiers not flagged as PII in the step before. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential Quasi-Identifiers: ['region', 'gender', 'age', 'height', 'weight', 'eat', 'schedule', 'howlong', 'retrieved_datetime']\n"
     ]
    }
   ],
   "source": [
    "# identify potential quasi-identifiers\n",
    "def identify_quasi_identifiers(dataframe, sensitive_columns):\n",
    "    quasi_identifiers = []\n",
    "    for column in dataframe.columns:\n",
    "        # Skip sensitive attributes\n",
    "        if column in sensitive_columns:\n",
    "            continue\n",
    "        \n",
    "        unique_count = dataframe[column].nunique()\n",
    "        # Assume a column could be a quasi-identifier if it's not unique for each record\n",
    "        # but has a high number of unique values.\n",
    "        if 1 < unique_count < len(dataframe):\n",
    "            quasi_identifiers.append(column)\n",
    "    \n",
    "    return quasi_identifiers\n",
    "\n",
    "# column names we know are PII\n",
    "sensitive_columns = ['athlete_id', 'name', 'team', 'affiliate', 'train', 'background', 'experience', 'fran', 'helen',  'grace', 'filthy50', 'fgonebad', 'run400', 'run5k', 'candj', 'snatch', 'deadlift', 'backsq', 'pullups']\n",
    "\n",
    "# Identify potential quasi-identifiers\n",
    "potential_quasi_identifiers = identify_quasi_identifiers(df, sensitive_columns)\n",
    "print(\"Potential Quasi-Identifiers:\", potential_quasi_identifiers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T13:16:42.023962600Z",
     "start_time": "2024-01-12T13:16:41.929740900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Apply k-anonymity: Choose a value for k\n",
    "- In this step we choose a value for k. \n",
    "- For example if we choose k = 3, then each combination of quasi-identifier values should apply to at least three records in the given dataset\n",
    "- a higher k value strengthens privacy by making re-identification more difficult, it also reduces the utility of the data by increasing information loss. \n",
    "- The choice of k thus represents a trade-off between privacy and utility that must be considered in the context of how the data will be used."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4. Use Generalization, Aggregation and Suppression as the transformation methods\n",
    "- Some data exploration has been done in #Assignment 1 already, so the intervals for different attributes and replacement values can be recycled. Some exploration must be done on top of it.\n",
    "- The attribute 'retrieved_datetime' can be removed, since all the entries are empty. Also, we standardize empty values.\n",
    "- The quasi-identifiers 'age', 'height', 'weight' will be anonymized using aggregation\n",
    "- Every attribute occuring less than 50 times in the entire dataset will be suppressed\n",
    "- The 'regions' will be mapped to the 7 continents\n",
    "- The 'schedule' attribute will be mapped to meaningful strings\n",
    "- The 'eat' attribute will be mapped to 4 different categories"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#drop the 'retrieved_datetime' column\n",
    "df = df.drop(columns=['retrieved_datetime'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T13:16:42.095703600Z",
     "start_time": "2024-01-12T13:16:42.014070900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Iterate over all columns in the DataFrame\n",
    "for column in df.columns:\n",
    "    # Replace empty strings with 'NA' in the column\n",
    "    df[column] = df[column].replace({'': 'NA'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T13:16:42.380501300Z",
     "start_time": "2024-01-12T13:16:42.096773400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Now, the aggregation\n",
    "- Using aggregation for attributes like 'age', 'weight' and 'height' makes sense in this context.\n",
    "- This provides a more concise representation of the data distribution while enabling to achieve k-anonymity."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Aggregate age, height and weight\n",
    "bins_age = [0, 30, 60, 100]\n",
    "labels_age = ['0-30', '31-60', '61+']\n",
    "\n",
    "\n",
    "bins_height = [0, 40, 70, 90]\n",
    "labels_height = ['0-40', '41-70', '71+']\n",
    "\n",
    "bins_weight = [0, 169, 199, 220]\n",
    "labels_weight = ['0-169', '170-199', '200+']\n",
    "\n",
    "# Apply binning\n",
    "df['age'] = pd.cut(df['age'], bins=bins_age, labels=labels_age)\n",
    "df['height'] = pd.cut(df['height'], bins=bins_height, labels=labels_height)\n",
    "df['weight'] = pd.cut(df['weight'], bins=bins_weight, labels=labels_weight)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T13:16:42.436236200Z",
     "start_time": "2024-01-12T13:16:42.381516400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Now, the suppression\n",
    "- By suppressing these rare occurrences, we reduce the risk of someone being able to link the data back to a specific individual"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# List of columns to apply the suppression\n",
    "columns_to_suppress = ['region', 'gender', 'age', 'height', 'weight', 'eat', 'schedule', 'howlong']\n",
    "\n",
    "for column in columns_to_suppress:\n",
    "    # Counting the frequency of each unique value in the column\n",
    "    value_counts = df[column].value_counts()\n",
    "\n",
    "    # Identifying values that occur less than 20 times\n",
    "    values_to_remove = value_counts[value_counts < 100].index\n",
    "\n",
    "    # Removing rows with these values\n",
    "    df = df[~df[column].isin(values_to_remove)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T13:16:43.082426200Z",
     "start_time": "2024-01-12T13:16:42.422454800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Now, the mapping: \n",
    "- The goal is to create broader categories that encapsulate the essence of the individual schedules without being overly specific.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique regions: ['South West' nan 'Southern California' 'South Central' 'Central East'\n",
      " 'Europe' 'North East' 'Africa' 'South East' 'Australia'\n",
      " 'Northern California' 'Latin America' 'Canada East' 'North Central'\n",
      " 'North West' 'Mid Atlantic' 'Canada West' 'Asia']\n"
     ]
    }
   ],
   "source": [
    "unique_regions = df['region'].unique()\n",
    "print(\"Unique regions:\", unique_regions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T13:16:43.095648100Z",
     "start_time": "2024-01-12T13:16:43.082426200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# mapping of regions \n",
    "region_to_continent = {\n",
    "    'South West': 'North America',\n",
    "    'Southern California': 'North America',\n",
    "    'South Central': 'North America',\n",
    "    'Central East': 'North America',\n",
    "    'Europe': 'International',\n",
    "    'North East': 'North America',\n",
    "    'Africa': 'International',\n",
    "    'South East': 'North America',\n",
    "    'Australia': 'International',\n",
    "    'Northern California': 'North America',\n",
    "    'Latin America': 'International',\n",
    "    'Canada East': 'North America',\n",
    "    'North Central': 'North America',\n",
    "    'North West': 'North America',\n",
    "    'Mid Atlantic': 'North America',\n",
    "    'Canada West': 'North America',\n",
    "    'Asia': 'International',\n",
    "    'NA': 'Other'  # 'NA' categorized as 'Other'\n",
    "}\n",
    "# Apply the mapping to the 'region' column\n",
    "df['region'] = df['region'].map(region_to_continent)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T13:16:43.151786500Z",
     "start_time": "2024-01-12T13:16:43.096659600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique schedules: ['I do multiple workouts in a day 2x a week|' nan\n",
      " 'I usually only do 1 workout a day|'\n",
      " 'I usually only do 1 workout a day|I strictly schedule my rest days|'\n",
      " 'I usually only do 1 workout a day|I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 3+ times a week|I typically rest fewer than 4 days per month|'\n",
      " 'I do multiple workouts in a day 3+ times a week|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 1x a week|I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 1x a week|I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 1x a week|'\n",
      " 'I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 3+ times a week|I strictly schedule my rest days|I typically rest 4 or more days per month|'\n",
      " 'I strictly schedule my rest days|'\n",
      " 'I do multiple workouts in a day 2x a week|I strictly schedule my rest days|I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 3+ times a week|I typically rest 4 or more days per month|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 3+ times a week|I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 2x a week|I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 1x a week|I typically rest fewer than 4 days per month|'\n",
      " 'I do multiple workouts in a day 1x a week|I strictly schedule my rest days|I typically rest 4 or more days per month|'\n",
      " 'I usually only do 1 workout a day|I typically rest fewer than 4 days per month|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 2x a week|I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 3+ times a week|I strictly schedule my rest days|I typically rest fewer than 4 days per month|'\n",
      " 'I do multiple workouts in a day 2x a week|I strictly schedule my rest days|'\n",
      " 'I do multiple workouts in a day 3+ times a week|I strictly schedule my rest days|'\n",
      " 'I typically rest fewer than 4 days per month|' 'Decline to answer|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 2x a week|I strictly schedule my rest days|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 1x a week|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 2x a week|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 1x a week|I strictly schedule my rest days|I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 2x a week|I typically rest fewer than 4 days per month|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 1x a week|I typically rest fewer than 4 days per month|'\n",
      " 'I usually only do 1 workout a day|I strictly schedule my rest days|I typically rest 4 or more days per month|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 3+ times a week|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 2x a week|I typically rest fewer than 4 days per month|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 1x a week|I strictly schedule my rest days|'\n",
      " 'I do multiple workouts in a day 1x a week|I strictly schedule my rest days|'\n",
      " 'I usually only do 1 workout a day|I do multiple workouts in a day 2x a week|I strictly schedule my rest days|I typically rest 4 or more days per month|'\n",
      " 'I usually only do 1 workout a day|I strictly schedule my rest days|I typically rest fewer than 4 days per month|'\n",
      " 'I strictly schedule my rest days|I typically rest 4 or more days per month|'\n",
      " 'I do multiple workouts in a day 2x a week|I strictly schedule my rest days|I typically rest fewer than 4 days per month|']\n"
     ]
    }
   ],
   "source": [
    "#Data exploration to map the schedules in a meaningful way\n",
    "unique_schedules = df['schedule'].unique()\n",
    "print(\"Unique schedules:\", unique_schedules)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T13:16:43.153784900Z",
     "start_time": "2024-01-12T13:16:43.127877900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#first mapping of the schedules to meaningful strings\n",
    "schedule_generalization = {\n",
    "    'I usually only do 1 workout a day|': 'Mixed Workout Frequency',\n",
    "    'I do multiple workouts in a day 1x a week|': 'Multiple Weekly Workouts',\n",
    "    'I do multiple workouts in a day 2x a week|': 'Multiple Weekly Workouts',\n",
    "    'I do multiple workouts in a day 3+ times a week|': 'Mixed Workout Frequency',\n",
    "    'I typically rest 4 or more days per month|': 'Regular Rest with Strict Scheduling',\n",
    "    'I typically rest fewer than 4 days per month|': 'Mixed Workout Frequency',\n",
    "    'I strictly schedule my rest days|': 'Regular Rest with Strict Scheduling',\n",
    "    'Decline to answer|': 'Other/Declined to Answer',\n",
    "    'I usually only do 1 workout a day|I strictly schedule my rest days|': 'Regular Rest with Strict Scheduling',\n",
    "    'I usually only do 1 workout a day|I typically rest 4 or more days per month|': 'Regular Rest with Strict Scheduling',\n",
    "    'I do multiple workouts in a day 3+ times a week|I typically rest fewer than 4 days per month|': 'Mixed Workout Frequency',\n",
    "    'I usually only do 1 workout a day|I do multiple workouts in a day 1x a week|I typically rest 4 or more days per month|': 'Mixed Workout Frequency',\n",
    "    'I do multiple workouts in a day 1x a week|I typically rest 4 or more days per month|': 'Regular Rest with Strict Scheduling',\n",
    "    'I do multiple workouts in a day 3+ times a week|I strictly schedule my rest days|I typically rest 4 or more days per month|': 'Regular Rest with Strict Scheduling',\n",
    "    'I do multiple workouts in a day 2x a week|I strictly schedule my rest days|I typically rest 4 or more days per month|': 'Regular Rest with Strict Scheduling',\n",
    "    'I do multiple workouts in a day 3+ times a week|I typically rest 4 or more days per month|': 'Regular Rest with Strict Scheduling',\n",
    "    'I usually only do 1 workout a day|I do multiple workouts in a day 3+ times a week|I typically rest 4 or more days per month|': 'Mixed Workout Frequency',\n",
    "    'I do multiple workouts in a day 2x a week|I typically rest 4 or more days per month|': 'Regular Rest with Strict Scheduling',\n",
    "    'I do multiple workouts in a day 1x a week|I typically rest fewer than 4 days per month|': 'Regular Rest with Strict Scheduling',\n",
    "    'I do multiple workouts in a day 1x a week|I strictly schedule my rest days|I typically rest 4 or more days per month|': 'Regular Rest with Strict Scheduling',\n",
    "    'I usually only do 1 workout a day|I typically rest fewer than 4 days per month|': 'Regular Rest with Strict Scheduling',\n",
    "    'I usually only do 1 workout a day|I do multiple workouts in a day 2x a week|I typically rest 4 or more days per month|': 'Mixed Workout Frequency',\n",
    "    'I usually only do 1 workout a day|I do multiple workouts in a day 1x a week|I strictly schedule my rest days|': 'Mixed Workout Frequency',\n",
    "    'I do multiple workouts in a day 1x a week|I strictly schedule my rest days|': 'Mixed Workout Frequency',\n",
    "    'I usually only do 1 workout a day|I do multiple workouts in a day 2x a week|I strictly schedule my rest days|I typically rest 4 or more days per month|': 'Regular Rest with Strict Scheduling',\n",
    "    'I usually only do 1 workout a day|I strictly schedule my rest days|I typically rest fewer than 4 days per month|': 'Regular Rest with Strict Scheduling',\n",
    "    'I strictly schedule my rest days|I typically rest 4 or more days per month|': 'Regular Rest with Strict Scheduling',\n",
    "    'I do multiple workouts in a day 2x a week|I strictly schedule my rest days|I typically rest fewer than 4 days per month|': 'Regular Rest with Strict Scheduling',\n",
    "    'Multiple Weekly Workouts': 'Mixed Workout Frequency',\n",
    "    'nan': 'Mixed Workout Frequency',\n",
    "    'Single Daily Workout': 'Mixed Workout Frequency',\n",
    "    'Strictly Scheduled Rest': 'Regular Rest with Strict Scheduling',\n",
    "    'Regular Rest Days': 'Regular Rest with Strict Scheduling',\n",
    "    'Frequent Workouts': 'Mixed Workout Frequency',\n",
    "    'Fewer Rest Days': 'Mixed Workout Frequency',\n",
    "    'Other/Declined to Answer': 'Mixed Workout Frequency',\n",
    "    'Mixed Workout Frequency': 'Mixed Workout Frequency',\n",
    "    'Scheduled Multiple Workouts': 'Mixed Workout Frequency',\n",
    "    'Regular Workout with Strict Rest Days': 'Regular Rest with Strict Scheduling',\n",
    "    'Regular Rest with Strict Scheduling': 'Regular Rest with Strict Scheduling',\n",
    "    'Frequent Workouts with Strict Rest Days': 'Regular Rest with Strict Scheduling',\n",
    "    'NA': 'NA'\n",
    "}\n",
    "\n",
    "# Apply the generalization to the 'schedule' column\n",
    "df['schedule'] = df['schedule'].map(schedule_generalization)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T13:16:43.191581200Z",
     "start_time": "2024-01-12T13:16:43.144076500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique schedules: ['Multiple Weekly Workouts' nan 'Mixed Workout Frequency'\n",
      " 'Regular Rest with Strict Scheduling' 'Other/Declined to Answer']\n"
     ]
    }
   ],
   "source": [
    "#Second Data exploration to map the schedules in a meaningful way\n",
    "unique_schedules = df['schedule'].unique()\n",
    "print(\"Unique schedules:\", unique_schedules)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T13:16:43.192583700Z",
     "start_time": "2024-01-12T13:16:43.172349200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T13:16:43.193584900Z",
     "start_time": "2024-01-12T13:16:43.183998400Z"
    }
   },
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique eat attributes: [nan 'I eat 1-3 full cheat meals per week|'\n",
      " \"I eat quality foods but don't measure the amount|\" 'I eat strict Paleo|'\n",
      " \"I eat quality foods but don't measure the amount|I eat 1-3 full cheat meals per week|\"\n",
      " 'I eat whatever is convenient|'\n",
      " \"I eat strict Paleo|I eat quality foods but don't measure the amount|\"\n",
      " 'I eat strict Paleo|I eat 1-3 full cheat meals per week|'\n",
      " \"I eat quality foods but don't measure the amount|I eat whatever is convenient|I eat 1-3 full cheat meals per week|\"\n",
      " \"I eat quality foods but don't measure the amount|I eat whatever is convenient|\"\n",
      " 'I eat whatever is convenient|I eat 1-3 full cheat meals per week|'\n",
      " 'Decline to answer|' 'I weigh and measure my food|'\n",
      " 'I weigh and measure my food|I eat strict Paleo|I eat 1-3 full cheat meals per week|'\n",
      " \"I eat strict Paleo|I eat quality foods but don't measure the amount|I eat 1-3 full cheat meals per week|\"\n",
      " 'I weigh and measure my food|I eat strict Paleo|'\n",
      " \"I weigh and measure my food|I eat quality foods but don't measure the amount|I eat 1-3 full cheat meals per week|\"\n",
      " 'I weigh and measure my food|I eat 1-3 full cheat meals per week|'\n",
      " \"I weigh and measure my food|I eat quality foods but don't measure the amount|\"\n",
      " 'I weigh and measure my food|I eat whatever is convenient|']\n"
     ]
    }
   ],
   "source": [
    "#Data exploration to map the eat attribute in a meaningful way\n",
    "unique_eat = df['eat'].unique()\n",
    "print(\"Unique eat attributes:\", unique_eat)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T13:16:43.241896Z",
     "start_time": "2024-01-12T13:16:43.189581900Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Mapping of eating habits to meaningful strings\n",
    "eat_generalization = {\n",
    "    'I eat 1-3 full cheat meals per week|': 'Cheat Meals/Other',\n",
    "    \"I eat quality foods but don't measure the amount|\": 'Quality Focused',\n",
    "    'I eat strict Paleo|': 'Diet-Conscious',\n",
    "    \"I eat quality foods but don't measure the amount|I eat 1-3 full cheat meals per week|\": 'Quality Focused',\n",
    "    'I eat whatever is convenient|': 'Convenience Eating',\n",
    "    \"I eat strict Paleo|I eat quality foods but don't measure the amount|\": 'Diet-Conscious',\n",
    "    'I eat strict Paleo|I eat 1-3 full cheat meals per week|': 'Diet-Conscious',\n",
    "    \"I eat quality foods but don't measure the amount|I eat whatever is convenient|I eat 1-3 full cheat meals per week|\": 'Quality Focused',\n",
    "    \"I eat quality foods but don't measure the amount|I eat whatever is convenient|\": 'Quality Focused',\n",
    "    'I eat whatever is convenient|I eat 1-3 full cheat meals per week|': 'Convenience Eating',\n",
    "    'Decline to answer|': 'Cheat Meals/Other',\n",
    "    'I weigh and measure my food|': 'Diet-Conscious',\n",
    "    'I weigh and measure my food|I eat strict Paleo|I eat 1-3 full cheat meals per week|': 'Diet-Conscious',\n",
    "    \"I eat strict Paleo|I eat quality foods but don't measure the amount|I eat 1-3 full cheat meals per week|\": 'Diet-Conscious',\n",
    "    'I weigh and measure my food|I eat strict Paleo|': 'Diet-Conscious',\n",
    "    \"I weigh and measure my food|I eat quality foods but don't measure the amount|I eat 1-3 full cheat meals per week|\": 'Diet-Conscious',\n",
    "    'I weigh and measure my food|I eat 1-3 full cheat meals per week|': 'Diet-Conscious',\n",
    "    \"I weigh and measure my food|I eat quality foods but don't measure the amount|\": 'Diet-Conscious',\n",
    "    'I weigh and measure my food|I eat whatever is convenient|': 'Diet-Conscious',\n",
    "    'NA': 'NA'\n",
    "}\n",
    "\n",
    "# Apply the generalization to the 'eat' column\n",
    "df['eat'] = df['eat'].map(eat_generalization)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T13:16:43.245604100Z",
     "start_time": "2024-01-12T13:16:43.202596Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique howlong attributes: ['4+ years|' nan '1-2 years|' '2-4 years|' '6-12 months|'\n",
      " 'Less than 6 months|' '1-2 years|2-4 years|'\n",
      " 'Less than 6 months|1-2 years|' '2-4 years|4+ years|'\n",
      " 'Decline to answer|' '6-12 months|1-2 years|']\n"
     ]
    }
   ],
   "source": [
    "#Data exploration to map the howlong attribute in a meaningful way\n",
    "unique_howlong = df['howlong'].unique()\n",
    "print(\"Unique howlong attributes:\", unique_howlong)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T13:16:43.260401800Z",
     "start_time": "2024-01-12T13:16:43.244598200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# mapping for the 'howlong' attribute\n",
    "howlong_generalization = {\n",
    "    '4+ years|': 'Experienced',\n",
    "    '1-2 years|': 'Experienced',\n",
    "    '2-4 years|': 'Experienced',\n",
    "    '6-12 months|': 'Novice',\n",
    "    'Less than 6 months|': 'Novice',\n",
    "    '1-2 years|2-4 years|': 'Experienced',\n",
    "    'Less than 6 months|1-2 years|': 'Novice',\n",
    "    '2-4 years|4+ years|': 'Experienced',\n",
    "    'Decline to answer|': 'NA',\n",
    "    '6-12 months|1-2 years|': 'Novice',\n",
    "    'NA': 'NA'\n",
    "}\n",
    "\n",
    "# Map the 'howlong' values to the categories\n",
    "df['howlong'] = df['howlong'].map(howlong_generalization)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T13:16:43.323473400Z",
     "start_time": "2024-01-12T13:16:43.260401800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5. Ensure that there are at least k records for each combination of quasi-identifiers\n",
    "- First, the lower the number of unique values per columnn, the closer we get to achieving k-anonymity in this algorithm. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 421097\n",
      "Unique values in each column:\n",
      " region      2\n",
      "gender      2\n",
      "age         2\n",
      "height      3\n",
      "weight      3\n",
      "eat         4\n",
      "schedule    4\n",
      "howlong     3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check how many unique values there are in each column\n",
    "num_rows = len(df)\n",
    "print(\"Number of rows:\", num_rows)\n",
    "\n",
    "columns_of_interest = ['region', 'gender', 'age', 'height', 'weight', 'eat', 'schedule', 'howlong']\n",
    "selected_df = df[columns_of_interest]\n",
    "\n",
    "unique_values = selected_df.nunique()\n",
    "print(\"Unique values in each column:\\n\", unique_values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T13:16:43.356144700Z",
     "start_time": "2024-01-12T13:16:43.294196400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 5.1 Last steps\n",
    "1. As a last step, we filter out the non-compliant rows. \n",
    "2. After this step, we've reached k-anonymity in our dataframe!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows dropped in this final step:  285\n",
      "The dataset satisfies k=2 anonymity.\n"
     ]
    }
   ],
   "source": [
    "# Group by quasi-identifiers\n",
    "grouped_df = df.groupby(['region', 'gender', 'age', 'height', 'weight', 'eat', 'schedule', 'howlong'], observed=True).size().reset_index(name='count')\n",
    "\n",
    "non_compliant_groups = grouped_df[grouped_df['count'] < 2]\n",
    "\n",
    "min_count1 = len(non_compliant_groups)\n",
    "# Merge with og DataFrame to flag non-compliant rows\n",
    "flagged_df = pd.merge(df, non_compliant_groups, on=['region', 'gender', 'age', 'height', 'weight', 'eat', 'schedule', 'howlong'], how='left', indicator=True)\n",
    "\n",
    "# Filter out non-compliant rows\n",
    "compliant_df = flagged_df[flagged_df['_merge'] == 'left_only'].drop(columns=['count', '_merge'])\n",
    "\n",
    "#group again\n",
    "grouped_compliant_df = compliant_df.groupby(['region', 'gender', 'age', 'height', 'weight', 'eat', 'schedule', 'howlong'], observed=True).size().reset_index(name='count')\n",
    "\n",
    "# Check the minimum count\n",
    "min_count = grouped_compliant_df['count'].min()\n",
    "\n",
    "# Verify if k-anonymity is achieved\n",
    "if min_count >= 2:\n",
    "    print(\"Number of rows dropped in this final step: \" , min_count1)\n",
    "    print(\"The dataset satisfies k=2 anonymity.\")\n",
    "    \n",
    "else:\n",
    "    print(\"The dataset does NOT satisfy k=2 anonymity.\")\n",
    "\n",
    "    # Display groups that occur only once\n",
    "    only_once = grouped_df[grouped_df['count'] == 1]\n",
    "    print(\"Groups that occur only once:\\n\", only_once)\n",
    "    \n",
    "    num_non_compliant = len(non_compliant_groups)\n",
    "    print(\"Number of groups not satisfying k=2 anonymity:\", num_non_compliant)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T13:16:43.962630800Z",
     "start_time": "2024-01-12T13:16:43.354633900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
